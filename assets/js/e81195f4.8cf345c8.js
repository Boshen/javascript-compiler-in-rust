"use strict";(self.webpackChunkjavascript_parser_in_rust=self.webpackChunkjavascript_parser_in_rust||[]).push([[348],{9613:(e,n,r)=>{r.d(n,{Zo:()=>c,kt:()=>f});var t=r(9496);function a(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function s(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function o(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?s(Object(r),!0).forEach((function(n){a(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function i(e,n){if(null==e)return{};var r,t,a=function(e,n){if(null==e)return{};var r,t,a={},s=Object.keys(e);for(t=0;t<s.length;t++)r=s[t],n.indexOf(r)>=0||(a[r]=e[r]);return a}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)r=s[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var l=t.createContext({}),p=function(e){var n=t.useContext(l),r=n;return e&&(r="function"==typeof e?e(n):o(o({},n),e)),r},c=function(e){var n=p(e.components);return t.createElement(l.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},d=t.forwardRef((function(e,n){var r=e.components,a=e.mdxType,s=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=p(r),f=a,m=d["".concat(l,".").concat(f)]||d[f]||u[f]||s;return r?t.createElement(m,o(o({ref:n},c),{},{components:r})):t.createElement(m,o({ref:n},c))}));function f(e,n){var r=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var s=r.length,o=new Array(s);o[0]=d;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i.mdxType="string"==typeof e?e:a,o[1]=i;for(var p=2;p<s;p++)o[p]=r[p];return t.createElement.apply(null,o)}return t.createElement.apply(null,r)}d.displayName="MDXCreateElement"},773:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>p});var t=r(2081),a=(r(9496),r(9613));const s={id:"parser",title:"Parser"},o=void 0,i={unversionedId:"parser",id:"parser",title:"Parser",description:"The parser we are going to construct is called a recursive descent parser,",source:"@site/docs/parser.md",sourceDirName:".",slug:"/parser",permalink:"/javascript-parser-in-rust/docs/parser",draft:!1,editUrl:"https://github.com/Boshen/javascript-parser-in-rust/tree/main/docs/docs/parser.md",tags:[],version:"current",frontMatter:{id:"parser",title:"Parser"},sidebar:"tutorialSidebar",previous:{title:"Abstract Syntax Tree",permalink:"/javascript-parser-in-rust/docs/ast"},next:{title:"Dealing with Errors",permalink:"/javascript-parser-in-rust/docs/errors"}},l={},p=[{value:"Helper functions",id:"helper-functions",level:2},{value:"Parse Functions",id:"parse-functions",level:2},{value:"Parsing Expressions",id:"parsing-expressions",level:2},{value:"Cover Grammar",id:"cover-grammar",level:2}],c={toc:p};function u(e){let{components:n,...r}=e;return(0,a.kt)("wrapper",(0,t.Z)({},c,r,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The parser we are going to construct is called a ",(0,a.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Recursive_descent_parser"},"recursive descent parser"),",\nit is the manual process of going down the grammar and building up the AST."),(0,a.kt)("p",null,"The parser starts simple, it holds the source code, the lexer, and the current token consumed from the lexer."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"pub struct Parser<'a> {\n    /// Source Code\n    source: &'a str,\n\n    lexer: Lexer<'a>,\n\n    /// Current Token consumed from the lexer\n    cur_token: Token,\n\n    /// The end range of the previous token\n    prev_node_end: usize,\n}\n\nimpl<'a> Parser<'a> {\n    pub fn new(source: &'a str) -> Self {\n        Self {\n            source,\n            lexer: Lexer::new(source),\n            cur_token: Token::default(),\n        }\n    }\n\n    pub fn parse(&mut self) -> Program<'a> {\n        Ok(Program {\n            node: Node {\n                start: 0,\n                end: self.source.len(),\n            }\n            body: vec![]\n        })\n    }\n}\n")),(0,a.kt)("h2",{id:"helper-functions"},"Helper functions"),(0,a.kt)("p",null,"The current token ",(0,a.kt)("inlineCode",{parentName:"p"},"cur_token: Token")," holds the current token returned from the lexer.\nWe'll make the parser code cleaner by adding some helper functions for navigating and inspecting this token."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"impl<'a> Parser<'a> {\n    fn start_node(&self) -> Node {\n        let token = self.cur_token();\n        Node::new(token.start, 0)\n    }\n\n    fn finish_node(&self, node: Node) -> Node {\n        Node::new(node.start, self.prev_node_end)\n    }\n\n    fn cur_token(&self) -> &Token {\n        &self.cur_token\n    }\n\n    fn cur_kind(&self) -> Kind {\n        self.cur_token.kind\n    }\n\n    /// Checks if the current index has token `Kind`\n    fn at(&self, kind: Kind) -> bool {\n        self.cur_kind() == kind\n    }\n\n    /// Advance and return true if we are at `Kind`\n    fn bump(&mut self, kind: Kind) {\n        if self.at(kind) {\n            self.advance();\n        }\n    }\n\n    /// Advance any token\n    fn bump_any(&mut self) {\n        self.advance();\n    }\n\n    /// Advance and return true if we are at `Kind`, return false otherwise\n    fn eat(&mut self, kind: Kind) -> bool {\n        if self.at(kind) {\n            self.advance();\n            return true;\n        }\n        false\n    }\n\n    /// Move to the next token\n    fn advance(&mut self) {\n        let token = self.lexer.next_token();\n        self.prev_node_end = self.cur_token.end;\n        self.cur_token = token;\n    }\n}\n")),(0,a.kt)("h2",{id:"parse-functions"},"Parse Functions"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"DebuggerStatement")," is the most simple statement to parse, so let's try and parse it and return a valid program"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"impl<'a> Parser<'a> {\n    pub fn parse(&mut self) -> Program {\n        let stmt = self.parse_debugger_statement();\n        let body = vec![stmt];\n        Ok(Program {\n            node: Node {\n                start: 0,\n                end: self.source.len(),\n            }\n            body,\n        })\n    }\n\n    fn parse_debugger_statement(&mut self) -> Statement {\n        let node = self.start_node();\n        self.bump_any();\n        Statement::DebuggerStatement {\n            node: self.finish_node(node),\n        }\n    }\n}\n")),(0,a.kt)("p",null,"All the other parse functions build on these primitive helper functions,\nfor example parsing the ",(0,a.kt)("inlineCode",{parentName:"p"},"while")," statement in swc:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust",metastring:"reference",reference:!0},"https://github.com/swc-project/swc/blob/554b459e26b24202f66c3c58a110b3f26bbd13cd/crates/swc_ecma_parser/src/parser/stmt.rs#L952-L970\n")),(0,a.kt)("h2",{id:"parsing-expressions"},"Parsing Expressions"),(0,a.kt)("p",null,"The grammar for expressions is deeply nested and recursive,\nwhich may cause stack overflow on long expressions (for example in ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/microsoft/TypeScript/blob/main/tests/cases/compiler/binderBinaryExpressionStressJs.ts"},"this TypeScript test"),"),"),(0,a.kt)("p",null,'To avoid recursion, we can use a technique called "Pratt Parsing". A more in-depth tutorial can be found ',(0,a.kt)("a",{parentName:"p",href:"https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html"},"here"),", written by the author of Rust-Analyzer.\nAnd a Rust version here in ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/rome/tools/blob/5a059c0413baf1d54436ac0c149a829f0dfd1f4d/crates/rome_js_parser/src/syntax/expr.rs#L442"},"Rome"),"."),(0,a.kt)("h2",{id:"cover-grammar"},"Cover Grammar"),(0,a.kt)("p",null,"Detailed in ",(0,a.kt)("a",{parentName:"p",href:"/blog/grammar#cover-grammar"},"cover grammar"),", there are times when we need to convert an ",(0,a.kt)("inlineCode",{parentName:"p"},"Expression")," to a ",(0,a.kt)("inlineCode",{parentName:"p"},"BindingIdentifier"),". Dynamic languages such as JavaScript can simply rewrite the node type:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-javascript",metastring:"reference",reference:!0},"https://github.com/acornjs/acorn/blob/11735729c4ebe590e406f952059813f250a4cbd1/acorn/src/lval.js#L11-L26\n")),(0,a.kt)("p",null,"But in Rust, we need to do a struct to struct transformation. A nice and clean way to do this is to use an trait."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"pub trait CoverGrammar<'a, T>: Sized {\n    fn cover(value: T, p: &mut Parser<'a>) -> Result<Self>;\n}\n")),(0,a.kt)("p",null,"The trait accepts ",(0,a.kt)("inlineCode",{parentName:"p"},"T")," as the input type, and ",(0,a.kt)("inlineCode",{parentName:"p"},"Self")," and the output type, so we can define the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"impl<'a> CoverGrammar<'a, Expression<'a>> for BindingPattern<'a> {\n    fn cover(expr: Expression<'a>, p: &mut Parser<'a>) -> Result<Self> {\n        match expr {\n            Expression::Identifier(ident) => Self::cover(ident.unbox(), p),\n            Expression::ObjectExpression(expr) => Self::cover(expr.unbox(), p),\n            Expression::ArrayExpression(expr) => Self::cover(expr.unbox(), p),\n            _ => Err(()),\n        }\n    }\n}\n\nimpl<'a> CoverGrammar<'a, ObjectExpression<'a>> for BindingPattern<'a> {\n    fn cover(obj_expr: ObjectExpression<'a>, p: &mut Parser<'a>) -> Result<Self> {\n        ...\n        BindingIdentifier::ObjectPattern(ObjectPattern { .. })\n    }\n}\n\nimpl<'a> CoverGrammar<'a, ArrayExpression<'a>> for BindingPattern<'a> {\n    fn cover(expr: ArrayExpression<'a>, p: &mut Parser<'a>) -> Result<Self> {\n        ...\n        BindingIdentifier::ArrayPattern(ArrayPattern { .. })\n    }\n}\n")),(0,a.kt)("p",null,"Then for anywhere we need to convert an ",(0,a.kt)("inlineCode",{parentName:"p"},"Expression")," to ",(0,a.kt)("inlineCode",{parentName:"p"},"BindingPattern"),",\ncall ",(0,a.kt)("inlineCode",{parentName:"p"},"BindingPattern::cover(expression)"),"."))}u.isMDXComponent=!0}}]);