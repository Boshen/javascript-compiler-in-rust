"use strict";(self.webpackChunkjavascript_compiler_in_rust=self.webpackChunkjavascript_compiler_in_rust||[]).push([[4],{9613:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var r=n(9496);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),u=c(n),m=a,h=u["".concat(s,".").concat(m)]||u[m]||d[m]||i;return n?r.createElement(h,o(o({ref:t},p),{},{components:n})):r.createElement(h,o({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var c=2;c<i;c++)o[c]=n[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},2351:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var r=n(2081),a=(n(9496),n(9613));const i={id:"lexer",title:"Lexer"},o=void 0,l={unversionedId:"lexer",id:"lexer",title:"Lexer",description:"The lexer, also known as tokenizer or scanner, is responsible for transforming source text to tokens.",source:"@site/docs/lexer.md",sourceDirName:".",slug:"/lexer",permalink:"/javascript-compiler-in-rust/docs/lexer",draft:!1,editUrl:"https://github.com/Boshen/javascript-compiler-in-rust/tree/main/docs/docs/lexer.md",tags:[],version:"current",frontMatter:{id:"lexer",title:"Lexer"},sidebar:"tutorialSidebar",previous:{title:"Architecture Overview",permalink:"/javascript-compiler-in-rust/docs/architecture"},next:{title:"Abstract Syntax Tree",permalink:"/javascript-compiler-in-rust/docs/ast"}},s={},c=[{value:"Peek",id:"peek",level:3},{value:"JavaScript",id:"javascript",level:2},{value:"Identifiers and Unicode",id:"identifiers-and-unicode",level:3},{value:"LL(1)",id:"ll1",level:3},{value:"Re-lex",id:"re-lex",level:3},{value:"Strict Mode",id:"strict-mode",level:3},{value:"Rust Optimizations",id:"rust-optimizations",level:2},{value:"Jump Table",id:"jump-table",level:3},{value:"Unicode Identifier Start",id:"unicode-identifier-start",level:3},{value:"Small Tokens",id:"small-tokens",level:3},{value:"String Interning",id:"string-interning",level:3}],p={toc:c};function d(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The lexer, also known as tokenizer or scanner, is responsible for transforming source text to tokens.\nThe tokens will later be consumed by the parser so we don't need to worry about whitespaces and comments in the original text."),(0,a.kt)("p",null,"Let's start simple and transform a single ",(0,a.kt)("inlineCode",{parentName:"p"},"+")," text into a token."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"#[derive(Debug, Clone, Copy, PartialEq)]\npub struct Token {\n    /// Token Type\n    pub kind: Kind,\n\n    /// Start offset in source\n    pub start: usize,\n\n    /// End offset in source\n    pub end: usize,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Kind {\n    Eof, // end of file\n    Plus,\n}\n")),(0,a.kt)("p",null,"A single ",(0,a.kt)("inlineCode",{parentName:"p"},"+")," will give you ",(0,a.kt)("inlineCode",{parentName:"p"},"[Token { kind: Kind::Plus, start: 0, end: 1 }, Token { kind: Kind::Eof, start: 1, end: 1 }]")),(0,a.kt)("p",null,"To loop through the string, we can either keep track of an index and pretend that we are writing C code,\nor we can take a look at the ",(0,a.kt)("a",{parentName:"p",href:"https://doc.rust-lang.org/std/primitive.str.html#"},"string documentation")," and find ourself a ",(0,a.kt)("inlineCode",{parentName:"p"},"Chars")," iterator to work with."),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},"Chars")," iterator abstracts away the tracking index and boundary checking to make you feel really safe."),(0,a.kt)("p",{parentName:"admonition"},"It gives you an ",(0,a.kt)("inlineCode",{parentName:"p"},"Option<char>")," when you call ",(0,a.kt)("inlineCode",{parentName:"p"},"chars.next()"),".\nBut please note that a ",(0,a.kt)("inlineCode",{parentName:"p"},"char")," is not a 0-255 ascii value,\nit is a utf8 unicode point value with the range of 0 to 0x10FFFF.")),(0,a.kt)("p",null,"Let's define a starter lexer abstraction"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"use std::str::Chars;\n\nstruct Lexer<'a> {\n    /// Source Text\n    source: &'a str,\n\n    /// Length of the original input string, in UTF-8 bytes\n    source_length: usize,\n\n    chars: Chars<'a>\n}\n\nimpl<'a> Lexer<'a> {\n    pub fn new(source: &'a str) -> Self {\n        Self {\n            source,\n            source_length: source.len(),\n            chars: source.chars()\n        }\n    }\n}\n")),(0,a.kt)("admonition",{type:"info"},(0,a.kt)("p",{parentName:"admonition"},"The lifetime ",(0,a.kt)("inlineCode",{parentName:"p"},"'a")," here indicates the iterator has a reference to somewhere, in this case it references to a ",(0,a.kt)("inlineCode",{parentName:"p"},"&'a str"),".")),(0,a.kt)("p",null,"To convert the source text to tokens, just keep calling ",(0,a.kt)("inlineCode",{parentName:"p"},"chars.next()")," and match on the returned ",(0,a.kt)("inlineCode",{parentName:"p"},"char"),"s.\nThe final token will always be ",(0,a.kt)("inlineCode",{parentName:"p"},"Kind::Eof"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust"},"impl<'a> Lexer<'a> {\n    fn read_next_kind(&mut self) -> Kind {\n        while let Some(c) = self.chars.next() {\n            match c {\n              '+' => return Kind::Plus,\n              _ => {}\n            }\n        }\n        Kind::Eof\n    }\n\n    fn read_next_token(&mut self) -> Token {\n        let start = self.source_length - self.current.chars.as_str().len();\n        let kind = self.read_next_kind();\n        let end = self.source_length - self.current.chars.as_str().len();\n        Token { kind, start, end }\n    }\n}\n")),(0,a.kt)("h3",{id:"peek"},"Peek"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-rust",metastring:"reference",reference:!0},"https://github.com/mozilla-spidermonkey/jsparagus/blob/master/crates/parser/src/lexer.rs#L1769-L1791\n")),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"javascript"},"JavaScript"),(0,a.kt)("p",null,"A lexer written in Rust is acutally really boring, it feels like writing C code\nwhere you write long chained if statements and check for each ",(0,a.kt)("inlineCode",{parentName:"p"},"char")," and then return the respective token."),(0,a.kt)("p",null,"But the fun begins when we start modifying it for JavaScript."),(0,a.kt)("p",null,"Let's open up the ",(0,a.kt)("a",{parentName:"p",href:"https://tc39.es/ecma262/"},"ECMAScript Language Specification")," and re-learn JavaScript."),(0,a.kt)("admonition",{type:"caution"},(0,a.kt)("p",{parentName:"admonition"},"I still remember the first time I opened up the specification and went into a little corner\nand cried for like five minutes because I couldn't understand what was going on.\nSo head over to my ",(0,a.kt)("a",{parentName:"p",href:"/blog/ecma-spec"},"guide on reading the specification")," if you are getting lost.")),(0,a.kt)("h3",{id:"identifiers-and-unicode"},"Identifiers and Unicode"),(0,a.kt)("p",null,"We mostly code in ascii,\nbut ",(0,a.kt)("a",{parentName:"p",href:"https://tc39.es/ecma262/#sec-ecmascript-language-source-code"},"Chapter 11 ECMAScript Language: Source Text"),"\nstates the source text should be in Unicode.\nAnd ",(0,a.kt)("a",{parentName:"p",href:"https://tc39.es/ecma262/#sec-names-and-keywords"},"Chapter 12.6 Names and Keywords"),"\nstates the identifiers are interpreted according to the Default Identifier Syntax given in Unicode Standard Annex #31.\nSpecifcally,"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-markup"},"UnicodeIDStart ::\n    any Unicode code point with the Unicode property \u201cID_Start\u201d\nUnicodeIDContinue ::\n    any Unicode code point with the Unicode property \u201cID_Continue\u201d\n")),(0,a.kt)("p",null,"This means that we can write ",(0,a.kt)("inlineCode",{parentName:"p"},"var \u0ca0_\u0ca0")," but not ",(0,a.kt)("inlineCode",{parentName:"p"},"var \ud83e\udd80")," because ",(0,a.kt)("inlineCode",{parentName:"p"},"\u0ca0_\u0ca0"),' has "ID_Start".'),(0,a.kt)("p",null,"I published the ",(0,a.kt)("a",{parentName:"p",href:"https://crates.io/crates/unicode-id-start"},"unicode-id-start")," for this exact purpose,\nand you can call ",(0,a.kt)("inlineCode",{parentName:"p"},"unicode_id_start::is_id_start(char)")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"unicode_id_start::is_id_continue(char)")," in your lexer for checking unicode."),(0,a.kt)("h3",{id:"ll1"},"LL(1)"),(0,a.kt)("h3",{id:"re-lex"},"Re-lex"),(0,a.kt)("h3",{id:"strict-mode"},"Strict Mode"),(0,a.kt)("hr",null),(0,a.kt)("h2",{id:"rust-optimizations"},"Rust Optimizations"),(0,a.kt)("h3",{id:"jump-table"},"Jump Table"),(0,a.kt)("h3",{id:"unicode-identifier-start"},"Unicode Identifier Start"),(0,a.kt)("h3",{id:"small-tokens"},"Small Tokens"),(0,a.kt)("h3",{id:"string-interning"},"String Interning"))}d.isMDXComponent=!0}}]);